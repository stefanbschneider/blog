{
  "cells": [
    {
      "cell_type": "raw",
      "id": "3c4a832b",
      "metadata": {},
      "source": [
        "---\n",
        "draft: true\n",
        "categories:\n",
        "- transformer\n",
        "- machine learning\n",
        "- deployment\n",
        "- HuggingFace\n",
        "date: '2024-02-09'\n",
        "date-modified: '2024-02-09'\n",
        "title: Building a Simple Question Answering App with HuggingFace\n",
        "description: Using pre-trained LLMs with HuggingFace and Gradio to build and deploy a simple question answering app in few lines of Python code.\n",
        "image: images/hf-logo-with-title.png\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "294d36c7",
      "metadata": {},
      "source": [
        "Large language models (LLMs) like GPT, BART, etc. have demonstrated incredible abilities in natural language.\n",
        "\n",
        "This blog post describes how you can use LLMs to build and deploy your own app in just a few lines of Python code with the [HuggingFace](https://huggingface.co/) ecosystem.\n",
        "HuggingFace provides pre-trained models, datasets, and other tools that are handy when working with machine learning models without having to understand all the underlying theory.\n",
        "If you are interested in how LLMs work, see [my other blog post on the underlying transformer architecture](https://stefanbschneider.github.io/blog/posts/understanding-transformers-attention/).\n",
        "\n",
        "As an example, the goal of this post is to build an app that answers questions about a given PDF document.\n",
        "The focus is on showing a simple proof of concept rather than high-quality answers.\n",
        "\n",
        "First, let's install the necessary dependencies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c066d39f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://gitlab%2Bdeploy-token-481912:****@gitlab.com/api/v4/projects/13674083/packages/pypi/simple\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.2.0-cp39-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio\n",
            "  Downloading gradio-4.17.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from pypdf) (4.9.0)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch)\n",
            "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from torch) (3.1.3)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
            "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy>=1.17 (from transformers)\n",
            "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.15.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers)\n",
            "  Downloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
            "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gradio-client==0.9.0 (from gradio)\n",
            "  Downloading gradio_client-0.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from gradio) (0.26.0)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
            "  Using cached importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from gradio) (2.1.5)\n",
            "Collecting matplotlib~=3.0 (from gradio)\n",
            "  Using cached matplotlib-3.8.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.13-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas<3.0,>=1.0 (from gradio)\n",
            "  Downloading pandas-2.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio)\n",
            "  Downloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.1.7 (from gradio)\n",
            "  Downloading ruff-0.2.1-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (23 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.27.0.post1-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.9.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
            "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio)\n",
            "  Downloading fonttools-4.48.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.9/158.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio)\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
            "  Downloading tzdata-2023.4-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.16.2 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.16.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
            "Collecting click<9.0.0,>=7.1.1 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich<14.0.0,>=10.11.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: h11>=0.8 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from httpx->gradio) (4.2.0)\n",
            "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from httpx->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from httpx->gradio) (1.0.2)\n",
            "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from httpx->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from requests->transformers) (2.2.0)\n",
            "Collecting mpmath>=0.19 (from sympy->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.17.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.17.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/Caskroom/miniforge/base/envs/blog/lib/python3.9/site-packages (from anyio->httpx->gradio) (1.2.0)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading pypdf-4.0.1-py3-none-any.whl (283 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp39-none-macosx_11_0_arm64.whl (59.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.17.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.9.0-py3-none-any.whl (306 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
            "Using cached matplotlib-3.8.2-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
            "Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.9.13-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.2/249.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.0-cp39-cp39-macosx_11_0_arm64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp39-cp39-macosx_11_0_arm64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.2.1-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (14.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-macosx_11_0_arm64.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.1-cp39-cp39-macosx_11_0_arm64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
            "Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Downloading python_multipart-0.0.7-py3-none-any.whl (22 kB)\n",
            "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Using cached contourpy-1.2.0-cp39-cp39-macosx_11_0_arm64.whl (242 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.48.1-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached kiwisolver-1.4.5-cp39-cp39-macosx_11_0_arm64.whl (66 kB)\n",
            "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached rich-13.7.0-py3-none-any.whl (240 kB)\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2023.4-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=4c085d78b46defd9bd9bf269e503e078a06c1d72b09ce345bf717885cc1a9b97\n",
            "  Stored in directory: /Users/stefanshschneider/Library/Caches/pip/wheels/1f/f1/8d/367922b023b526b7c2ced5db30932def7b18cf39d7ac6e8572\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pytz, pydub, mpmath, ffmpy, websockets, tzdata, tqdm, toolz, tomlkit, sympy, shellingham, semantic-version, safetensors, ruff, regex, python-multipart, pypdf, pyparsing, pydantic-core, pillow, orjson, numpy, networkx, mdurl, kiwisolver, importlib-resources, fsspec, fonttools, filelock, cycler, colorama, click, annotated-types, aiofiles, uvicorn, typer, torch, starlette, pydantic, pandas, markdown-it-py, huggingface-hub, contourpy, tokenizers, rich, matplotlib, gradio-client, fastapi, transformers, altair, gradio\n",
            "Successfully installed aiofiles-23.2.1 altair-5.2.0 annotated-types-0.6.0 click-8.1.7 colorama-0.4.6 contourpy-1.2.0 cycler-0.12.1 fastapi-0.109.2 ffmpy-0.3.1 filelock-3.13.1 fonttools-4.48.1 fsspec-2024.2.0 gradio-4.17.0 gradio-client-0.9.0 huggingface-hub-0.20.3 importlib-resources-6.1.1 kiwisolver-1.4.5 markdown-it-py-3.0.0 matplotlib-3.8.2 mdurl-0.1.2 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.4 orjson-3.9.13 pandas-2.2.0 pillow-10.2.0 pydantic-2.6.1 pydantic-core-2.16.2 pydub-0.25.1 pyparsing-3.1.1 pypdf-4.0.1 python-multipart-0.0.7 pytz-2024.1 regex-2023.12.25 rich-13.7.0 ruff-0.2.1 safetensors-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 sympy-1.12 tokenizers-0.15.1 tomlkit-0.12.0 toolz-0.12.1 torch-2.2.0 tqdm-4.66.1 transformers-4.37.2 typer-0.9.0 tzdata-2023.4 uvicorn-0.27.0.post1 websockets-11.0.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U pypdf torch transformers gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a4089c9",
      "metadata": {},
      "source": [
        "# Question Answering with HuggingFace\n",
        "\n",
        "We can read the text of PDF document with `pypdf`. As an example, I'm using the author version of a [paper](https://ieeexplore.ieee.org/document/9789886) I wrote on [`mobile-env`](https://github.com/stefanbschneider/mobile-env). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4828c301",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'mobile-env : An Open Platform for Reinforcement\\nLearning in Wireless Mobile Networks\\nStefan Schneider, Stefan Werner\\nPaderborn University, Germany\\n{stschn, stwerner}@mail.upb.deRamin Khalili, Artur Hecker\\nHuawei Technologies, Germany\\n{ramin.khalili, artur.hecker}@huawei.comHolger Karl\\nHasso Plattner Institute,\\nUniversity of Potsdam, Germany\\nholger.karl@hpi.de\\nAbstract —Recent reinforcement learning approaches for con-\\ntinuous control in wireless mobile networks have shown im-\\npressive results. But due to the lack of open and compatible\\nsimulators, authors typically create their own simulation en-\\nvironments for training and evaluation. This is cumbersome\\nand time-consuming for authors and limits reproducibility and\\ncomparability, ultimately impeding progress in the ﬁeld.\\nTo this end, we propose mobile-env , a simple and open platform\\nfor training, evaluating, and comparing reinforcement learning\\nand conventional approaches for continuous control in mobile\\nwireless networks. mobile-env is lightweight and implements\\nthe common OpenAI Gym interface and additional wrappers,\\nwhich allows connecting virtually any single-agent or multi-agent\\nreinforcement learning framework to the environment. While\\nmobile-env provides sensible default values and can be used out\\nof the box, it also has many conﬁguration options and is easy to\\nextend. We therefore believe mobile-env to be a valuable platform\\nfor driving meaningful progress in autonomous coordination of\\nwireless mobile networks.\\nIndex'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from typing import Union\n",
        "from pypdf import PdfReader\n",
        "\n",
        "\n",
        "def get_text_from_pdf(pdf_file: Union[str, Path]) -> str:\n",
        "    \"\"\"Read the PDF from the given path and return a string with its entire content.\"\"\"\n",
        "    reader = PdfReader(pdf_file)\n",
        "\n",
        "    # Extract text from all pages\n",
        "    full_text = \"\"\n",
        "    for page in reader.pages:\n",
        "        full_text += page.extract_text()\n",
        "    return full_text\n",
        "\n",
        "# Read and print parts of the PDF\n",
        "pdf_text = get_text_from_pdf(\"mobileenv_author_version.pdf\")\n",
        "pdf_text[:1500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8662ed07",
      "metadata": {},
      "source": [
        "Now we can create a question answering pipeline using HuggingFace, loading a pre-trained model. Then we can ask some questions, providing the PDF text as context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2325a098",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(task=\"question-answering\", model=\"deepset/tinyroberta-squad2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "871b3b95",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.9885759353637695,\n",
              " 'start': 16482,\n",
              " 'end': 16499,\n",
              " 'answer': 'GitHub repository'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_answerer(\"What is mobile-env?\", pdf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "89f9bbc6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.9702701568603516, 'start': 3555, 'end': 3561, 'answer': 'Python'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_answerer(\"What programming language is mobile-env written in?\", pdf_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ced00482",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'score': 0.5076063275337219,\n",
              " 'start': 12526,\n",
              " 'end': 12557,\n",
              " 'answer': 'more ﬂexible, better documented'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_answerer(\"What is the main difference between mobile-env and other simulators?\", pdf_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0df359f1",
      "metadata": {},
      "source": [
        "The pipeline returns a dict, where the answer is a quote from the given context, here the PDF document. This is called *extractive* question answering.\n",
        "\n",
        "It also provides a score indicating the model's confindence in the answer and the start/end index from where the answer is quoted. \n",
        "\n",
        "That's it! Let's see how we can build a simple app on top of this.\n",
        "\n",
        "# Building an App with Gradio\n",
        "\n",
        "[Gradio](https://www.gradio.app/) allows building simple apps tailored for machine learning use cases.\n",
        "You can define the inputs, a function to where to pass these inputs, and how to display the functions outputs.\n",
        "\n",
        "Here, our inputs are the PDF document and the question.\n",
        "The function loads the document and passes the question and text to the pre-trained model.\n",
        "It then outputs the models answer to the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f5a8daee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def answer_doc_question(pdf_file, question):\n",
        "    pdf_text = get_text_from_pdf(pdf_file)\n",
        "    answer = question_answerer(question, pdf_text)\n",
        "    return answer[\"answer\"]\n",
        "\n",
        "pdf_input = gr.File(file_types=[\".pdf\"], label=\"Upload a PDF document and ask a question about it.\")\n",
        "question = gr.Textbox(label=\"Type a question regarding the uploaded document here.\")\n",
        "gr.Interface(fn=answer_doc_question, inputs=[pdf_input, question], outputs=\"text\").launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a903f86",
      "metadata": {},
      "source": [
        "If you run this locally, you should see a rendered app based on the question answering pipeline we built above!\n",
        "\n",
        "# Deploying the app in HuggingFace Spaces\n",
        "\n",
        "You can easily host the app on [HuggingFace Spaces](https://huggingface.co/spaces), which provide free (and slow) hosting (or fast paid hosting).\n",
        "\n",
        "You simply create a new space under your account and add an `app.py`, which contains all code above. The requirements go into a `requirements.txt`. That's it!\n",
        "\n",
        "This is the app we built here: [https://huggingface.co/spaces/stefanbschneider/pdf-question-answering](https://huggingface.co/spaces/stefanbschneider/pdf-question-answering)\n",
        "\n",
        "<script\n",
        "\ttype=\"module\"\n",
        "\tsrc=\"https://gradio.s3-us-west-2.amazonaws.com/4.17.0/gradio.js\"\n",
        "></script>\n",
        "\n",
        "<gradio-app src=\"https://stefanbschneider-pdf-question-answering.hf.space\"></gradio-app>\n",
        "\n",
        "\n",
        "# What's Next?\n",
        "\n",
        "* [Read about the underlying transformer architecture powering most LLMs](https://stefanbschneider.github.io/blog/posts/understanding-transformers-attention/)\n",
        "* Improve the quality of the question answering app. Some ideas:\n",
        "    * Fine-tune the pre-trained model on a domain dataset, eg, [Arxiv Q&A](https://huggingface.co/datasets/taesiri/arxiv_qa)\n",
        "    * [Domain adaptation by fine-tuning a masked model directly on the document](https://huggingface.co/learn/nlp-course/en/chapter7/3)\n",
        "    * Using the [document-question-answering pipeline on HuggingFace](https://huggingface.co/tasks/document-question-answering)\n",
        "    * Trying a model that supports *generative* question answering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f513d0",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
